maybe this is the point where i need the renderer command thing

-submit 3d shit
-submit 2d shit
-renderer draws the 3d shit then the 2d shit#
	-that way I can enable and disable depth buffering in one place

the 'systems' should just be responsible for passing and preparing the data from the components

-maybe I do need to it the cherno way then. Have a class for the API calls, a class for the command queue, a class for the higher level render shit
	-the problem with the way I have done it with the systems is that a) I can'tr guarentee the order and b) it's happening in two places


I think the 'systems' should just be responsible for parsing the data from the components. That's it
Looks like I'll need to refactor my rendering system.

Render2D/3DSystem
	-Takes all data from the components and parses it into the Renderer

Render:
	-High level
	-No  abstraction
	-Will recieve all draw commands from systems within clove
	-Can sort / optimise everything
	-Submit those commands into a command queue
	-Manages shaders
	-Only API will basically be to submit things

RenderCommand:
	-Stores all commands from the renderer ready to be submitted to the renderer api
	-Will have the API for all the commands Clove supports (Clear, Draw w/e)

RenderAPI:
	-Contains all of the api commands
	-Is the abstraction



I can do without the RenderCommand but I might as well if I'm restructuring everything. 
The important part is seperating the API call from the high level render shinanagins and not giving too responsibility to the systems

Is there anything I want to do to change the context while I'm in here. should this just be merged into the render api abstraction?
-The only thing the context currently does is abstract opengl stuff and cause film flams for dx
-Will have to put more thought into this



basic flow:
-begin scene
-submit a bunch of stuff to the renderer
-end scene
-renderer does what it needs to then submits it all to the render command queue
-render command queue will make all the api calls (potentially on a seperate thread)

flow notes:
From look at DX it has a deferred context and vulkan has a command buffer.
The idea behind them is that the commands will be built on a different
(probably main) thread and then played back on the render thread. OpenGL
seems a bit different in the fact that multi thread is done by you and
through the contexts that you'll create (WGL, GLX, EGL etc.). You make
a context per thread and then 'share lists' (VBO/IBO, shaders etc.). This
will probably require a massive refactor of the context system. I think 
that'll have to be a part 2 so I can do the UI. It's important to keep this
in mind when setting up the skeleton but at the moment I imagine the
command will just be a straight wrapper on the RenderAPI. 

I guess an important thing to think about is if I'll even use these built-in
methods. It looks like the RenderCommand will queue everything and then the
RenderAPI will be called on another thread. I guess at this point it is up
to me on how this happens then. I need to restructure my Renderer with this
in mind:

-Need a class to handle the higher level rendering (Batching. Sorting. Culling etc.) 	- Renderer
-Need a class to queue up all of the commands recieved from the renderer		- RenderCommand
-Need a class to execute all of the commands recieved from the command queue		- RenderAPI

Idle notes:
-I imagine if I wasn't going to do the multi-threading stuff then the api would just inherit from the command queue
-I think binding a bindable could rightfully be considered a command (it would have to be played back right?)

The next big think is how to get the device on DX to create the bindables - might be worth having a peak at vulkan - I did, it looks like it just works like opengl (free functions)
So unless Metal does something wildly different I should expect it to work like that, so DX will have to do something special. Metal is just all sort of different so fuck that for a long time.

This is the big think now. I think I'll need to add a special case for DX to grab the device.
